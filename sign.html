<!DOCTYPE html>
<html>
<head>
    
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sign Language to Text Translator</title>
    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <!-- Custom CSS -->
    <link rel="stylesheet" href="material-components-web.min.css">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="yasmin.css" />
    <!-- <style>
        #container {
            display: flex;
            font-family: Verdana, sans-serif;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 90vh;
        }

        #videoElement {
            width: 550px;
            height: 300px;
        }
   #textOutput {
    width: 950px;
    height: 350px;
    background-color: rgb(255, 255, 255);
    border-radius: 30px;
    padding: 30px 40px;
    margin: 0 auto;
    text-align: left;
    font-size: 25px;
    margin-top: 30px;
    border:1px solid black;
    box-shadow: 8px 8px 0px 0px rgba(0, 0, 0, 0.403);
    transition: 0.3s;

        }

    </style>
    <script>
        //camera
        function startCamera() {
            var video = document.getElementById("videoElement");

            if (navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(function (stream) {
                        video.srcObject = stream;
                        // Automatically translate to text
                        setInterval(translateToText, 1000); // Translate every second
                    })
                    .catch(function (error) {
                        console.log("Error accessing camera: " + error);
                    });
            }
        }

        // Translate sign language to text
        function translateToText() {
            // Get video element and canvas
            var video = document.getElementById("videoElement");
            var canvas = document.createElement("canvas");
            var context = canvas.getContext("2d");

            // Set canvas size to match video size
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            // Draw video frame on canvas
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Get the image data from the canvas
            var imageData = context.getImageData(0, 0, canvas.width, canvas.height);

            // Convert the image data to sign language text
            // You would need to implement your own logic or use a sign language recognition library for this step

            // Update the text field with the translated text
            document.getElementById("textOutput").value = translatedText;
        }

        // Automatically start the camera
        window.addEventListener("DOMContentLoaded", startCamera);
    </script> -->
</head>
<body>

    <header class="header">
        <nav class="navbar">
          <img src="img/logo.png" class="img">
          <h4 class="logo"><a href="#"> <div class="center">EasyCommunication </div></a></h4>
          <input type="checkbox" id="menu-toggle" />
          <label for="menu-toggle" id="hamburger-btn">
            <!-- Add your SVG code here -->
          </label>
          <ul class="links">
            <li><a href="homepage.html">Home</a></li>
            <li><a href="keyboard.html">keyboard</a></li>
            <li><a href="img.html">voice command </a></li>
            <li><a href="sign.html">sign language</a></li>
          </ul>
        </nav>
      </header>

      <!-- <h1 style="text-align: center;">Arabic Hand Sign Gestures Recognition <br> using the Convolutional Neural Network & MediaPipe</h1> -->
    <!--  -->
    <section id="demos" class="invisible">
        <h2><br>Arabic Hand Sign Gestures Recognition</h2>
        <br>
        <div id="liveView" class="videoView">
            <div class="centered-container">
            <button id="webcamButton" class="mdc-button mdc-button--raised" style="background-color: #CFE7EB; border: 2px #CFE7EB; color: #fff; font-size: 20px; border-radius: 30px; padding: 15px 15px;">
                <span class="mdc-button__ripple"></span>
                <span class="mdc-button__label">ENABLE WEBCAM</span>
            </button>
            </div>
            <br>
            <div style="position: relative;">
            <video id="webcam" autoplay playsinline></video>
            <canvas class="output_canvas" id="output_canvas" width="1280" height="720" style="position: absolute; left: 0px; top: 0px;"></canvas>
            <p id='gesture_output' class="output"></p>
            </div>
        </div>
    </section>

    <!-- <div id="container">
        <video id="videoElement" autoplay></video>
        <br>
        <label for="textOutput">Translated Text:</label>
        <textarea id="textOutput" rows="5" cols="50" readonly>character:
sentence:</textarea> -->
    </div>
</body>
<script type="module">
    import {
    GestureRecognizer,
    FilesetResolver,
    DrawingUtils
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    const demosSection = document.getElementById("demos");
    let gestureRecognizer= GestureRecognizer;
    let runningMode = "IMAGE";
    let enableWebcamButton= HTMLButtonElement;
    let webcamRunning = false;
    const videoHeight = "360px";
    const videoWidth = "480px";

    // Before we can use HandLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createGestureRecognizer = async () => {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
      );
      gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "gesture_recognizer.task",
          delegate: "GPU"
        },
        runningMode: runningMode
      });
      demosSection.classList.remove("invisible");
    };
    createGestureRecognizer();


    /********************************************************************
    // Continuously grab image from webcam stream and detect it.
    ********************************************************************/

    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const gestureOutput = document.getElementById("gesture_output");

    // Check if webcam access is supported.
    function hasGetUserMedia() {
      return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
    }

    // If webcam supported, add event listener to button for when user
    // wants to activate it.
    if (hasGetUserMedia()) {
      enableWebcamButton = document.getElementById("webcamButton");
      enableWebcamButton.addEventListener("click", enableCam);
    } else {
      console.warn("getUserMedia() is not supported by your browser");
    }

    // Enable the live webcam view and start detection.
    function enableCam(event) {
      if (!gestureRecognizer) {
        alert("Please wait for gestureRecognizer to load");
        return;
      }

      if (webcamRunning === true) {
        webcamRunning = false;
        enableWebcamButton.innerText = "ENABLE PREDICTIONS";
      } else {
        webcamRunning = true;
        enableWebcamButton.innerText = "DISABLE PREDICTIONS";
        sentence = '';
        previousLetter = '';
      }

      // getUsermedia parameters.
      const constraints = {
        video: true
      };

      // Activate the webcam stream.
      navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      });
    }

    let lastVideoTime = -1;
    let results = undefined;

    let previousLetter = '';
    let sentence = '';

    // make a list
    let letter_list = [];

    async function predictWebcam() {
      const webcamElement = document.getElementById("webcam");
      // Now let's start detecting the stream.
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
      }
      let nowInMs = Date.now();
      if (video.currentTime !== lastVideoTime) {
        lastVideoTime = video.currentTime;
        results = gestureRecognizer.recognizeForVideo(video, nowInMs);
      }

      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      const drawingUtils = new DrawingUtils(canvasCtx);

      canvasElement.style.height = videoHeight;
      webcamElement.style.height = videoHeight;
      canvasElement.style.width = videoWidth;
      webcamElement.style.width = videoWidth;

      if (results.landmarks) {
        for (const landmarks of results.landmarks) {
          drawingUtils.drawConnectors(
            landmarks,
            GestureRecognizer.HAND_CONNECTIONS,
            {
              color: "#00FF00",
              lineWidth: 5
            }
          );
          drawingUtils.drawLandmarks(landmarks, {
            color: "#FF0000",
            lineWidth: 2
          });
        }
      }
      const arabicMapping = {
        'Seen': 'س',
        'Ain': 'ع',
        'Al': 'ال',
        'Waw': 'و',
        'Teh': 'ت',
        'Zain': 'ز',
        'Dad': 'ض',
        'Heh': 'ه',
        'Lam': 'ل',
        'Meem': 'م',
        'Theh': 'ث',
        'Laa': 'لا',
        'Jeem': 'ج',
        'Reh': 'ر',
        'Beh': 'ب',
        'Kaf': 'ك',
        'Feh': 'ف',
        'Alef': 'ا',
        'Tah': 'ط',
        'Thal': 'ذ',
        'Sheen': 'ش',
        'Khah': 'خ',
        'Hah': 'ح',
        'Ghain': 'غ',
        'Noon': 'ن',
        'Sad': 'ص',
        'Teh_Marbuta': 'ة',
        'Qaf': 'ق',
        'Dal': 'د',
        'Zah': 'ظ',
        'Yeh': 'ي'
      };


      canvasCtx.restore();
      if (results.gestures.length > 0) {
        gestureOutput.style.display = "block";
        gestureOutput.style.width = videoWidth;

        let categoryName = arabicMapping[results.gestures[0][0].categoryName];

        if (categoryName === undefined) {
          categoryName = "none";
        }
        const categoryScore = parseFloat(
          results.gestures[0][0].score * 100
        ).toFixed(2);
        const handedness = results.handednesses[0][0].displayName;

        if (categoryScore > 55) {
          const currentLetter = arabicMapping[results.gestures[0][0].categoryName] || '';
          // if (currentLetter !== 'none' && currentLetter !== previousLetter) {
          if (currentLetter !== 'none' && currentLetter !== '') {
            // sentence += currentLetter;
            letter_list.push(currentLetter);
            // previousLetter = currentLetter;
          }
        }
        // console.log(letter_list);

        if (letter_list.length > 35) {
          // check which letter is repeated the most
          let counts = {};
          let compare = 0;
          let mostFrequent;
          for (let i = 0, len = letter_list.length; i < len; i++) {
            let word = letter_list[i];

            if (counts[word] === undefined) {
              counts[word] = 1;
            } else {
              counts[word] = counts[word] + 1;
            }
            if (counts[word] > compare) {
              compare = counts[word];
              mostFrequent = letter_list[i];
            }
          }
          // console.log(mostFrequent);

          if (mostFrequent !== 'none' && mostFrequent !== previousLetter) {
            sentence += mostFrequent;
            previousLetter = mostFrequent;
            letter_list = [];
          }
        }

        gestureOutput.innerText = `Character: ${categoryName}\n Sentence: ${sentence}\n Confidence: ${categoryScore}`;
      } else {
        gestureOutput.style.display = "none";

        if (sentence.length > 0) {
          sentence += ' ';
          previousLetter = '';
          letter_list = [];
        }
      }

      // Call this function again to keep predicting when the browser is ready.
      if (webcamRunning === true) {
        window.requestAnimationFrame(predictWebcam);
      }
    }

  </script>
</html>
